import os
import requests
from bs4 import BeautifulSoup
import hashlib

class AvitoParser:
    def __init__(self, cache_dir="cache"):
        self.price_value = None
        self.full_address = None
        self.rooms = None
        self.total_area = None
        self.floor = None
        self.type_estate = None  # –î–æ–±–∞–≤–ª—è–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –¥–ª—è —Ç–∏–ø–∞ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏
        self.cache_dir = cache_dir
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –∫—ç—à–∞, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
        os.makedirs(self.cache_dir, exist_ok=True)

    def _get_cache_filename(self, url):
        # –•—ç—à–∏—Ä—É–µ–º URL –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
        url_hash = hashlib.md5(url.encode()).hexdigest()
        return os.path.join(self.cache_dir, f"{url_hash}.html")

    def _download_html(self, url):
        cache_file = self._get_cache_filename(url)

        # –ï—Å–ª–∏ —Ñ–∞–π–ª —Å –∫—ç—à–µ–º —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, —á–∏—Ç–∞–µ–º –∏–∑ –Ω–µ–≥–æ
        if os.path.exists(cache_file):
            #print(f'–§–∞–π–ª {cache_file} —Å—É—â–µ—Å—Ç–≤—É–µ—Ç')
            with open(cache_file, "r", encoding="utf-8") as file:
                return file.read()

        # –ï—Å–ª–∏ —Ñ–∞–π–ª–∞ –Ω–µ—Ç, —Å–∫–∞—á–∏–≤–∞–µ–º HTML
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        }
        response = requests.get(url, headers=headers)
        print(f'–ê–¥—Ä–µ—Å –Ω–æ–≤—ã–π, —Å–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª: {cache_file}')
        if response.status_code != 200:
            raise Exception(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {response.status_code}")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º HTML –≤ –∫—ç—à
        with open(cache_file, "w", encoding="utf-8") as file:
            file.write(response.text)

        return response.text
    
    def _process_address(self, address):
        parts = address.split(',')
        if '—É–ª.' in parts[-2]:
            processed_parts = [part + '\n üìç' for part in parts[:-2]]
            processed_parts.append(f"{parts[-2]},{parts[-1]}")
        else:
            processed_parts = [part + '\n üìç' for part in parts[:-1]]
            processed_parts.append(parts[-1])
        address = ''.join(processed_parts)
        return address

    def _extract_type_estate(self, title):
        # –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Å—Ç—Ä–æ–∫ –ø–æ–∏—Å–∫–∞ –∏ –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        estate_types_mapping = {
            '–∫–≤–∞—Ä—Ç–∏—Ä–∞': '–ö–≤–∞—Ä—Ç–∏—Ä–∞',
            '–ö–≤–∞—Ä—Ç–∏—Ä–∞-—Å—Ç—É–¥–∏—è': '–°—Ç—É–¥–∏—è',
            '–°–≤–æ–±. –ø–ª–∞–Ω–∏—Ä–æ–≤–∫–∞': '–°–≤–æ–±–æ–¥–Ω–∞—è –ø–ª–∞–Ω–∏—Ä–æ–≤–∫–∞',
            '–ö–æ–º–Ω–∞—Ç–∞': '–ö–æ–º–Ω–∞—Ç–∞',
            '–î–æ–º': '–î–æ–º',
            '–î–∞—á–∞': '–î–∞—á–∞',
            '–ö–æ—Ç—Ç–µ–¥–∂': '–ö–æ—Ç—Ç–µ–¥–∂',
            '–¢–∞—É–Ω—Ö–∞—É—Å': '–¢–∞—É–Ω—Ö–∞—É—Å',
            '–ò–ñ–°': '–ò–ñ–°',
            '–°–ù–¢, –î–ù–ü': '–°–ù–¢',
            '–ì–∞—Ä–∞–∂,': '–ì–∞—Ä–∞–∂',
            '–ú–∞—à–∏–Ω–æ–º–µ—Å—Ç–æ': '–ú–∞—à–∏–Ω–æ–º–µ—Å—Ç–æ'
        }
        # –ò—â–µ–º —Ç–∏–ø –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏ –≤ –∑–∞–≥–æ–ª–æ–≤–∫–µ
        for search_string, estate_type in estate_types_mapping.items():
            if search_string in title:
                return estate_type
        
        return "–ù–µ —É–∫–∞–∑–∞–Ω–æ"

    def _extract_param(self, params_soup, param_name):
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ –∏–∑ –±–ª–æ–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.
        :param params_soup: BeautifulSoup-–æ–±—ä–µ–∫—Ç –±–ª–æ–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.
        :param param_name: –ù–∞–∑–≤–∞–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞.
        :return: –ó–Ω–∞—á–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ –∏–ª–∏ None, –µ—Å–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω.
        """
        for li in params_soup.find_all('li', class_='params-paramsList__item-_2Y2O'):
            span = li.find('span', class_='styles-module-noAccent-l9CMS')
            if span and param_name in span.text:
                return span.next_sibling.strip()
        return None  # –ï—Å–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω

    def parse(self, url):
        # –°–∫–∞—á–∏–≤–∞–µ–º HTML
        html = self._download_html(url)

        # –ü–∞—Ä—Å–∏–º HTML
        soup = BeautifulSoup(html, 'html.parser')

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        title = soup.find('title').text if soup.find('title') else "–ù–µ —É–∫–∞–∑–∞–Ω–æ"
        self.type_estate = self._extract_type_estate(title)  # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–∏–ø –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏

        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ü–µ–Ω—É
        price_span = soup.find('span', {'itemprop': 'price'})
        self.price_value = price_span.get('content', '–ù–µ —É–∫–∞–∑–∞–Ω–æ') if price_span else '–ù–µ —É–∫–∞–∑–∞–Ω–æ'

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, –µ—Å–ª–∏ –±–ª–æ–∫ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        if params_block := soup.find('div', {'data-marker': 'item-view/item-params'}):
            params_soup = BeautifulSoup(params_block.decode_contents(), 'html.parser')

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            self.rooms = self._extract_param(params_soup, "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–Ω–∞—Ç")
            self.total_area = self._extract_param(params_soup, "–û–±—â–∞—è –ø–ª–æ—â–∞–¥—å")
            self.floor = self._extract_param(params_soup, "–≠—Ç–∞–∂:")
            self.plot_area = self._extract_param(params_soup, "–ü–ª–æ—â–∞–¥—å —É—á–∞—Å—Ç–∫–∞")
            self.house_type = self._extract_param(params_soup, "–¢–∏–ø –¥–æ–º–∞")
            self.wall_material = self._extract_param(params_soup, "–ú–∞—Ç–µ—Ä–∏–∞–ª —Å—Ç–µ–Ω")
            self.build_year = self._extract_param(params_soup, "–ì–æ–¥ –ø–æ—Å—Ç—Ä–æ–π–∫–∏")
            self.distance_to_center = self._extract_param(params_soup, "–†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–æ —Ü–µ–Ω—Ç—Ä–∞ –≥–æ—Ä–æ–¥–∞")
            self.land_category = self._extract_param(params_soup, "–ö–∞—Ç–µ–≥–æ—Ä–∏—è –∑–µ–º–µ–ª—å")
            self.garage_type = self._extract_param(params_soup, "–¢–∏–ø –≥–∞—Ä–∞–∂–∞")
            self.parking_type = self._extract_param(params_soup, "–¢–∏–ø –º–∞—à–∏–Ω–æ–º–µ—Å—Ç–∞")
            self.room_area = self._extract_param(params_soup, "–ü–ª–æ—â–∞–¥—å –∫–æ–º–Ω–∞—Ç—ã")
            self.rooms_in_apartment = self._extract_param(params_soup, "–ö–æ–º–Ω–∞—Ç –≤ –∫–≤–∞—Ä—Ç–∏—Ä–µ")
            self.house_area = self._extract_param(params_soup, "–ü–ª–æ—â–∞–¥—å –¥–æ–º–∞")
            self.floors_in_house = self._extract_param(params_soup, "–≠—Ç–∞–∂–µ–π –≤ –¥–æ–º–µ")

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∞–¥—Ä–µ—Å
        address_element = soup.find('span', class_='style-item-address__string-wt61A')
        self.full_address = address_element.text.strip() if address_element else "–ù–µ —É–∫–∞–∑–∞–Ω–æ"
        self.full_address = self._process_address(self.full_address)

        # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—É—é —Å—Ç—Ä–æ–∫—É
        result = [f"‚õ≥Ô∏è {self.full_address}"]
        result.append(f"üè† –¢–∏–ø –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏: {self.type_estate}")
        result.append(f"üíµ {self.price_value}‚ÇΩ")

        # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, –µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ None
        if self.rooms:
            result.append(f"üö™ –ö–æ–º–Ω–∞—Ç: {self.rooms}")
        if self.total_area:
            result.append(f"üìê –û–±—â–∞—è –ø–ª–æ—â–∞–¥—å: {self.total_area} –º¬≤")
        if self.floor:
            result.append(f"ü™ú –≠—Ç–∞–∂: {self.floor}")
        if self.house_type:
            result.append(f"üè° –¢–∏–ø –¥–æ–º–∞: {self.house_type}")
        if self.wall_material:
            result.append(f"üß± –ú–∞—Ç–µ—Ä–∏–∞–ª —Å—Ç–µ–Ω: {self.wall_material}")
        if self.build_year:
            result.append(f"üìÖ –ì–æ–¥ –ø–æ—Å—Ç—Ä–æ–π–∫–∏: {self.build_year}")
        if self.distance_to_center:
            result.append(f"üìç –†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–æ —Ü–µ–Ω—Ç—Ä–∞: {self.distance_to_center}")
        if self.plot_area:
            result.append(f"üå≥ –ü–ª–æ—â–∞–¥—å —É—á–∞—Å—Ç–∫–∞: {self.plot_area}")
        if self.land_category:
            result.append(f"üèûÔ∏è –ö–∞—Ç–µ–≥–æ—Ä–∏—è –∑–µ–º–µ–ª—å: {self.land_category}")
        if self.garage_type:
            result.append(f"üöó –¢–∏–ø –≥–∞—Ä–∞–∂–∞: {self.garage_type}")
        if self.parking_type:
            result.append(f"üÖøÔ∏è –¢–∏–ø –º–∞—à–∏–Ω–æ–º–µ—Å—Ç–∞: {self.parking_type}")
        if self.room_area:
            result.append(f"üõèÔ∏è –ü–ª–æ—â–∞–¥—å –∫–æ–º–Ω–∞—Ç—ã: {self.room_area}")
        if self.rooms_in_apartment:
            result.append(f"üè† –ö–æ–º–Ω–∞—Ç –≤ –∫–≤–∞—Ä—Ç–∏—Ä–µ: {self.rooms_in_apartment}")
        if self.house_area:
            result.append(f"üè† –ü–ª–æ—â–∞–¥—å –¥–æ–º–∞: {self.house_area}")
        if self.floors_in_house:
            result.append(f"üè† –≠—Ç–∞–∂–µ–π –≤ –¥–æ–º–µ: {self.floors_in_house}")
        result.append('\n')
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –ø–µ—Ä–µ–Ω–æ—Å–∞–º–∏
        return "\n".join(result)

    def _extracted_from_parse_20(self, params_block):
        params_soup = BeautifulSoup(params_block.decode_contents(), 'html.parser')
        self.rooms = self._extract_param(params_soup, "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–Ω–∞—Ç")
        self.total_area = self._extract_param(params_soup, "–û–±—â–∞—è –ø–ª–æ—â–∞–¥—å")
        self.floor = self._extract_param(params_soup, "–≠—Ç–∞–∂")

        # –û—á–∏—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        self.total_area = self.total_area.replace("\u00A0–º\u00B2", "").replace(" –º\u00B2", "")
        self.floor = self.floor.replace(" –∏–∑ ", "/")

if __name__ == "__main__":
    url0 = 'https://www.avito.ru/ekaterinburg/kvartiry/1-k._kvartira_406_m_69_et._4574477371?context=H4sIAAAAAAAA_wEmANn_YToxOntzOjE6IngiO3M6MTY6Ik9Ra1c5RzE3TUY5c0R2NW8iO32sRl6AJgAAAA'
    url1 = 'https://www.avito.ru/ekaterinburg/kvartiry/kvartira-studiya_57_m_1625_et._7243069890?context=H4sIAAAAAAAA_wEmANn_YToxOntzOjE6IngiO3M6MTY6InlOcXhNSHk4bHg4MkxjWlQiO33jAkacJgAAAA'
    url2 = 'https://www.avito.ru/ekaterinburg/kvartiry/svob._planirovka_50_m_44_et._5122336744?context=H4sIAAAAAAAA_wEmANn_YToxOntzOjE6IngiO3M6MTY6IlpGY3FYb0UxMkk3VUxjMFAiO31DR3s7JgAAAA'
    url3 = 'https://www.avito.ru/verhnyaya_salda/komnaty/komnata_135_m_v_1-k._45_et._1333252089?context=H4sIAAAAAAAA_wEmANn_YToxOntzOjE6IngiO3M6MTY6Imt5dWRNS29pa25CeWg0VXYiO30K98gkJgAAAA'
    url4 = 'https://www.avito.ru/verhnee_dubrovo/doma_dachi_kottedzhi/dom_1274_m_na_uchastke_76_sot._7252674869?context=H4sIAAAAAAAA_wEmANn_YToxOntzOjE6IngiO3M6MTY6Ik5od2N2Z1BHaVJhaVpVOHAiO31XgMClJgAAAA'
    url5 = 'https://www.avito.ru/dvurechensk/doma_dachi_kottedzhi/dacha_18_m_na_uchastke_10_sot._3203306502?context=H4sIAAAAAAAA_wEmANn_YToxOntzOjE6IngiO3M6MTY6IjJzRTNyWEZDQVBvYkRKdUgiO30NWGFWJgAAAA'
    url6 = 'https://www.avito.ru/ekaterinburg/doma_dachi_kottedzhi/kottedzh_200_m_na_uchastke_8_sot._3080749310?context=H4sIAAAAAAAA_wEmANn_YToxOntzOjE6IngiO3M6MTY6IlVsSnpzSWphTVd5c29tdXgiO33Z6DWlJgAAAA'
    url7 = 'https://www.avito.ru/verhnee_dubrovo/doma_dachi_kottedzhi/taunhaus_134_m_na_uchastke_2_sot._7221450986?context=H4sIAAAAAAAA_wEmANn_YToxOntzOjE6IngiO3M6MTY6IlhnajNUQ0lVZU8yeFBTRkwiO33NMB-aJgAAAA'
    url8 = 'https://www.avito.ru/verhnyaya_pyshma/zemelnye_uchastki/uchastok_6_sot._izhs_1387175700?context=H4sIAAAAAAAA_wEmANn_YToxOntzOjE6IngiO3M6MTY6ImcxMEFvZ3hrU1FWUDIxenMiO320OK3wJgAAAA'
    url9 = 'https://www.avito.ru/ekaterinburg/zemelnye_uchastki/uchastok_5_ga_snt_dnp_4611091619?context=H4sIAAAAAAAA_wEmANn_YToxOntzOjE6IngiO3M6MTY6InRxbFgwQ0R4cEl0Q0NuSmsiO303-IQAJgAAAA'
    url10 = 'https://www.avito.ru/pervouralsk/garazhi_i_mashinomesta/garazh_22_m_4837910861?context=H4sIAAAAAAAA_wEmANn_YToxOntzOjE6IngiO3M6MTY6IlZtNVUyYjdXT3hyQVdxbUciO30bKPsiJgAAAA'
    url11 = 'https://www.avito.ru/ekaterinburg/garazhi_i_mashinomesta/mashinomesto_15_m_4547294076?context=H4sIAAAAAAAA_wEmANn_YToxOntzOjE6IngiO3M6MTY6IjhrOVdjRmdwVmRoMkFtQloiO30uAaclJgAAAA'
    parser = AvitoParser()
    print(parser.parse(url0))
    print(parser.parse(url1))
    print(parser.parse(url2))
    print(parser.parse(url3))
    print(parser.parse(url4))
    print(parser.parse(url5))
    print(parser.parse(url6))
    print(parser.parse(url7))
    print(parser.parse(url8))
    print(parser.parse(url9))
    print(parser.parse(url10))
    print(parser.parse(url11))